# EN Special Term Project : Automatic Trash Sorter
-> Group 2   
-> Supervised by Dr.Tharaka Smarasinghe


ğŸ§­ AI Trash Classification with Raspberry Pi â€” Full Roadmap
âš™ï¸ Stage 1 â€” Core Foundations (Week 1â€“2)

Goal: Learn the essential tools â€” Python, OpenCV, and Raspberry Pi basics.

ğŸ“˜ Learn

Python fundamentals: data types, loops, NumPy, file I/O

OpenCV basics: image loading, color detection, contour detection

Raspberry Pi setup: OS installation, SSH, camera setup

ğŸ§© Practice

Use cv2.VideoCapture(0) to display live video.

Write scripts to:

Convert images to grayscale

Detect color regions (plastic often has shiny color)

Capture & save images when a button is pressed

ğŸ“ Resources

Python Crash Course (freeCodeCamp)

OpenCV Python Course

Getting Started with Raspberry Pi Camera

ğŸ¤– Stage 2 â€” Machine Learning & Computer Vision Concepts (Week 2â€“3)

Goal: Understand how image classification models work.

ğŸ“˜ Learn

What is machine learning vs. deep learning

How CNNs (Convolutional Neural Networks) process images

Dataset â†’ Training â†’ Testing â†’ Model evaluation

ğŸ§© Practice

Train a simple classifier on your laptop using scikit-learn or TensorFlow.

Try classifying MNIST digits or CIFAR-10 images.

Visualize CNN layers using TensorBoard.

ğŸ“ Resources

Deep Learning Crash Course â€“ freeCodeCamp

Google ML Crash Course

Kaggle: Intro to Machine Learning

ğŸ“¸ Stage 3 â€” Build Your Dataset (Week 3â€“4)

Goal: Capture and label images of trash items.

ğŸ“˜ Learn

Data collection best practices (consistent lighting, angles, background)

Folder structure for datasets

Data augmentation (flips, rotations, scaling)

ğŸ§© Practice

Capture at least 200â€“300 images per class using your Pi or phone.
Classes:

dataset/
  â”œâ”€ paper/
  â”œâ”€ plastic/
  â”œâ”€ metal/
  â””â”€ organic/


Use ImageDataGenerator to augment data.

Split into train/test (80%/20%).

ğŸ“ Tools

OpenCV for capturing images

LabelImg (if you decide to extend to object detection later)

ğŸ§  Stage 4 â€” Model Training (Week 4â€“5)

Goal: Train a CNN or use transfer learning with MobileNetV2.

ğŸ“˜ Learn

TensorFlow/Keras basics

Transfer learning and fine-tuning

Loss functions, accuracy metrics

ğŸ§© Practice

Load a pretrained model:

base = tf.keras.applications.MobileNetV2(weights='imagenet', include_top=False, input_shape=(224,224,3))


Add classification layers for 4 classes.

Train and evaluate on your dataset.

Save as .h5 and convert to .tflite:

converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()
open("trash_classifier.tflite", "wb").write(tflite_model)

ğŸ“ Resources

TensorFlow Transfer Learning Tutorial

Kaggle: Computer Vision Course

ğŸ’» Stage 5 â€” Deploy Model on Raspberry Pi (Week 6)

Goal: Run the .tflite model in real time on your Raspberry Pi.

ğŸ“˜ Learn

TensorFlow Lite Interpreter

Real-time inference with Pi Camera

Optimizing model performance (quantization, resizing input)

ğŸ§© Practice

Install dependencies:

pip install tensorflow-lite opencv-python


Run inference:

import tensorflow as tf, cv2, numpy as np
interpreter = tf.lite.Interpreter(model_path="trash_classifier.tflite")
interpreter.allocate_tensors()


Show classification results on the live video feed with cv2.putText().

ğŸ“ Resources

TensorFlow Lite Raspberry Pi Guide

YouTube: TensorFlow Lite on Raspberry Pi

ğŸ”Œ Stage 6 â€” Hardware Integration (Week 7)

Goal: Control LEDs, servos, or motors based on detected class.

ğŸ“˜ Learn

Using Raspberry Pi GPIO pins with Python

Servo and relay control

Mapping AI outputs to hardware actions

ğŸ§© Practice

Blink LEDs for each detected category.

Move servo to drop item into the correct bin.

if label == "Plastic": servo_pin.write(90)
elif label == "Paper": servo_pin.write(45)


Optional: use ultrasonic sensor to detect object presence.

ğŸ“ Resources

GPIOZero Python Docs

Raspberry Pi Servo Motor Tutorial

âš¡ Stage 7 â€” Optimization & Expansion (Week 8+)

Goal: Make it faster, more accurate, and smarter.

ğŸ“˜ Learn

Model quantization (INT8, FP16)

Using Google Coral TPU or Raspberry Pi 5 NPU

Combining non-vision sensors (metal detector, moisture sensor)

ğŸ§© Practice

Quantize model with TensorFlow Lite converter.

Use hybrid approach:

Metal detector â†’ quickly identify metallic waste

Camera AI â†’ classify other types

ğŸ“ Resources

TensorFlow Lite Optimization Guide

Coral USB Accelerator Docs

ğŸš€ Stage 8 â€” Complete System Project

Goal: Build a working prototype.

ğŸ§© Combine:

Raspberry Pi camera for classification

GPIO-controlled servos for sorting

Optional LCD/OLED display to show results

Enclosure with 4 bins (paper, plastic, metal, organic)

ğŸ“˜ Bonus Additions

Web dashboard using Flask or Streamlit

Data logging (how much of each category per day)

Add sound feedback (â€œPlastic detected!â€)

ğŸ—“ï¸ Suggested Timeline Summary
Week	Stage	Focus	Key Outcome
1â€“2	Foundations	Python + OpenCV + Pi setup	Capture and display images
2â€“3	ML Concepts	CNN + datasets	Understand image classification
3â€“4	Dataset	Collect 4-class dataset	Dataset ready for training
4â€“5	Model Training	MobileNetV2 fine-tuning	Trained .tflite model
6	Deployment	TensorFlow Lite on Pi	Real-time classification
7	Hardware Integration	GPIO + Servo + Sorting	Automated sorting
8+	Optimization	Quantization + Hybrid sensing	Faster, more reliable system
ğŸ§© Optional Add-ons

Use YOLOv8 + Pi 5 for object detection.

Add cloud logging via Firebase.

Integrate Arduino for precise actuation control.
